# -*- coding: utf-8 -*-
"""FruitImageClassifier_ShaikNeelofar.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-pDxt_4eEiP4hpuuVxn3v1_oywhF4f5W
"""

# Install kaggle CLI (only needed if you will download from Kaggle in Colab)
!pip install -q kaggle

# Create a directory for Kaggle credentials and move kaggle.json there.
# After running this cell, Colab will show a file upload prompt — upload your kaggle.json.
import os
os.makedirs('/root/.kaggle', exist_ok=True)
from google.colab import files
print("Please upload your kaggle.json file (it contains your Kaggle API token).")
uploaded = files.upload()  # upload kaggle.json interactively

# Move uploaded kaggle.json to the right place and set permissions
for fn in uploaded.keys():
    os.replace(fn, f'/root/.kaggle/{fn}')
    os.chmod(f'/root/.kaggle/{fn}', 0o600)

# Verify kaggle works
!kaggle --version

# Download the Fruits dataset from Kaggle (this is the 'fruits' dataset).
# This will download many files — the 100x100 version is included in the dataset.
!kaggle datasets download -d moltean/fruits

# Unzip the downloaded file (overwrite safe)
!unzip -q -o fruits.zip -d "/content/drive/MyDrive/Colab Notebooks/FruitImageClassifierUsingCNN_ShaikNeelofar/fruits_dataset"

# Let's list the main folders to find the 'Training' and 'Test' directories
import os
base_dir = '/content/drive/MyDrive/Colab Notebooks/FruitImageClassifierUsingCNN_ShaikNeelofar/fruits_dataset/fruits-360_100x100/fruits-360'  # typical path in this dataset
print("Exists?", os.path.exists(base_dir))
print("Contents:", os.listdir(base_dir)[:20])

# The dataset has 'Training' and 'Test' directories with one folder per fruit class
train_dir = os.path.join(base_dir, 'Training')
test_dir = os.path.join(base_dir, 'Test')

# List available classes (folders)
all_classes = sorted(os.listdir(train_dir))
print("Number of classes available:", len(all_classes))
print("First 30 classes:", all_classes[:30])

# Choose 10 classes to work with for speed.
# Option A: edit the list to pick the classes you like.
# Option B (automatic): pick first 10 classes (but you can replace them).
selected_classes = all_classes[:10]
# Print selected classes so you can confirm or edit them.
print("Selected 10 classes for the subset:")
for i, c in enumerate(selected_classes, 1):
    print(i, c)

import shutil
from pathlib import Path

# Destination path for our small 10-class dataset
subset_base = '/content/drive/MyDrive/Colab Notebooks/FruitImageClassifierUsingCNN_ShaikNeelofar/fruits_10class'
train_dst = os.path.join(subset_base, 'train')
val_dst = os.path.join(subset_base, 'val')
test_dst = os.path.join(subset_base, 'test')
# Create directories
for d in [train_dst, val_dst, test_dst]:
    os.makedirs(d, exist_ok=True)

# Helper: copy a fraction of images for train/val/test from original dataset
import random

def copy_images_for_class(class_name, train_ratio=0.8, val_ratio=0.1):
    src_class_dir = os.path.join(train_dir, class_name)  # images are in Training for training set
    all_imgs = sorted(os.listdir(src_class_dir))
    random.seed(42)
    random.shuffle(all_imgs)
    n = len(all_imgs)
    n_train = int(train_ratio * n)
    n_val = int(val_ratio * n)
    train_imgs = all_imgs[:n_train]
    val_imgs = all_imgs[n_train:n_train + n_val]
    test_imgs = sorted(os.listdir(os.path.join(test_dir, class_name)))  # use provided Test images for test
    # Create class dirs in destinations
    os.makedirs(os.path.join(train_dst, class_name), exist_ok=True)
    os.makedirs(os.path.join(val_dst, class_name), exist_ok=True)
    os.makedirs(os.path.join(test_dst, class_name), exist_ok=True)
    # Copy train images
    for img in train_imgs:
        shutil.copy(os.path.join(src_class_dir, img), os.path.join(train_dst, class_name, img))
    # Copy validation images
    for img in val_imgs:
        shutil.copy(os.path.join(src_class_dir, img), os.path.join(val_dst, class_name, img))
    # Copy test images (from dataset Test folder)
    for img in test_imgs:
        shutil.copy(os.path.join(test_dir, class_name, img), os.path.join(test_dst, class_name, img))
# Create subset for each selected class
for cls in selected_classes:
    copy_images_for_class(cls)

# Quick sanity check: print counts
for split, path in [('train', train_dst), ('val', val_dst), ('test', test_dst)]:
    total = sum(len(files) for r, d, files in os.walk(path))
    print(f"{split} images:", total)

# We'll use Keras ImageDataGenerator for easy preprocessing and augmentation.
from tensorflow.keras.preprocessing.image import ImageDataGenerator

IMG_SIZE = (100, 100)  # dataset images are 100x100 already
BATCH_SIZE = 32
# Training generator with augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,            # normalize pixel values to [0,1]
    rotation_range=15,         # small rotations
    width_shift_range=0.1,     # horizontal shifts
    height_shift_range=0.1,    # vertical shifts
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)
# Validation and test generator: only rescale
val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dst,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',  # multi-class
    shuffle=True
)

val_generator = val_datagen.flow_from_directory(
    val_dst,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

test_generator = val_datagen.flow_from_directory(
    test_dst,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

# Save class indices mapping (useful for predictions)
class_indices = train_generator.class_indices
print("Class indices:", class_indices)

"""## ***CNN Baseline***"""

# Build a small CNN with Keras Functional API for clarity
import tensorflow as tf
from tensorflow.keras import layers, models

num_classes = len(selected_classes)

inputs = layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))  # 3 channels (RGB)
# Block 1
x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(inputs)  # 32 filters, 3x3 kernel
x = layers.MaxPooling2D((2,2))(x)  # downsample

# Block 2
x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)
x = layers.MaxPooling2D((2,2))(x)

# Block 3
x = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x)
x = layers.MaxPooling2D((2,2))(x)

# Flatten and Dense layers
x = layers.Flatten()(x)
x = layers.Dense(128, activation='relu')(x)  # dense layer for learning non-linear combinations
x = layers.Dropout(0.5)(x)  # dropout to reduce overfitting

outputs = layers.Dense(num_classes, activation='softmax')(x)  # final layer with softmax for probabilities

model = models.Model(inputs=inputs, outputs=outputs, name='simple_cnn')
model.summary()

# Compile with Adam optimizer and categorical crossentropy (multi-class classification)
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
# Callbacks: early stopping and model checkpoint
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/FruitImageClassifierUsingCNN_ShaikNeelofar/best_simple_cnn.keras'
callbacks = [
    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
    ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True)
]
# Train the model. Start with 15-20 epochs (should be fine for the subset)
EPOCHS = 20
history = model.fit(
    train_generator,
    epochs=EPOCHS,
    validation_data=val_generator,
    callbacks=callbacks
)

import matplotlib.pyplot as plt

# Accuracy plot
plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='train_acc')
plt.plot(history.history['val_accuracy'], label='val_acc')
plt.title('Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Loss plot
plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.title('Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Get predictions on test set
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

# Predict probabilities and convert to class indices
test_steps = test_generator.samples // test_generator.batch_size + 1
y_prob = model.predict(test_generator, steps=test_steps, verbose=1)
y_pred = np.argmax(y_prob, axis=1)

# True labels
y_true = test_generator.classes[:len(y_pred)]
# Print classification report (precision, recall, f1)
target_names = list(class_indices.keys())
print(classification_report(y_true, y_pred, target_names=target_names, digits=4))

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
print("Confusion matrix:\n", cm)

# Plot confusion matrix heatmap
import seaborn as sns
plt.figure(figsize=(10,8))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=target_names, yticklabels=target_names, cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Save (already saved best by checkpoint); also save full model for inference
model.save('/content/drive/MyDrive/Colab Notebooks/FruitImageClassifierUsingCNN_ShaikNeelofar/fruits_cnn_full_model.keras')

from tensorflow.keras.preprocessing import image
import numpy as np

# Map index to class name
idx_to_class = {v:k for k,v in class_indices.items()}
def predict_fruit(img_path, model, img_size=IMG_SIZE):
    """
    Load an image from img_path, preprocess it and predict using the provided Keras model.
    Returns top prediction and confidence.
    """
    img = image.load_img(img_path, target_size=img_size)          # load and resize
    x = image.img_to_array(img)                                   # convert to array (H,W,C)
    x = x / 255.0                                                 # scale pixels to [0,1]
    x = np.expand_dims(x, axis=0)                                 # add batch dimension
    probs = model.predict(x)[0]                                   # prediction probabilities
    top_idx = np.argmax(probs)
    return idx_to_class[top_idx], float(probs[top_idx])
# Example usage: replace '/path/to/image.jpg' with an image file you upload to Colab
uploaded_img = files.upload()  # upload an image to Colab
img_path = list(uploaded_img.keys())[0]
print(predict_fruit(img_path, model))

"""## ***VGG16***"""

from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models, optimizers

IMG_SHAPE = (100, 100, 3)   # same as before
NUM_CLASSES = len(selected_classes)

# Load VGG16 without the top fully-connected layers, with pretrained ImageNet weights
vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)

# Freeze all convolutional layers for feature extraction
for layer in vgg_base.layers:
    layer.trainable = False

# Build the classification model on top of VGG16
x = layers.Flatten()(vgg_base.output)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dropout(0.5)(x)
output = layers.Dense(NUM_CLASSES, activation='softmax')(x)

vgg_model = models.Model(inputs=vgg_base.input, outputs=output, name='vgg16_fruit')
vgg_model.summary()

vgg_model.compile(
    optimizer=optimizers.Adam(learning_rate=1e-3),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

vgg_checkpoint = '/content/drive/MyDrive/Colab Notebooks/FruitImageClassifierUsingCNN_ShaikNeelofar/best_vgg16.keras'
callbacks = [
    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
    ModelCheckpoint(vgg_checkpoint, monitor='val_loss', save_best_only=True)
]

EPOCHS = 15
history_vgg = vgg_model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=EPOCHS,
    callbacks=callbacks
)

# Unfreeze the last few convolutional layers to fine-tune
for layer in vgg_base.layers[-4:]:  # unfreeze last 4 layers
    layer.trainable = True

# Use a very low learning rate for fine-tuning
vgg_model.compile(
    optimizer=optimizers.Adam(learning_rate=1e-5),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
# Train again for a few epochs
history_vgg_ft = vgg_model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=5,
    callbacks=callbacks
)

from google.colab import drive
drive.mount('/content/drive')

# Evaluate on test set
vgg_loss, vgg_acc = vgg_model.evaluate(test_generator)
print(f"VGG16 Test Accuracy: {vgg_acc*100:.2f}%")

# Plot training curves for feature extraction + fine-tuning combined
import matplotlib.pyplot as plt

plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plt.plot(history_vgg.history['accuracy'] + history_vgg_ft.history['accuracy'], label='train_acc')
plt.plot(history_vgg.history['val_accuracy'] + history_vgg_ft.history['val_accuracy'], label='val_acc')
plt.title('VGG16 Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1,2,2)
plt.plot(history_vgg.history['loss'] + history_vgg_ft.history['loss'], label='train_loss')
plt.plot(history_vgg.history['val_loss'] + history_vgg_ft.history['val_loss'], label='val_loss')
plt.title('VGG16 Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

test_steps = test_generator.samples // test_generator.batch_size + 1
y_prob = vgg_model.predict(test_generator, steps=test_steps)
y_pred = np.argmax(y_prob, axis=1)
y_true = test_generator.classes[:len(y_pred)]

target_names = list(class_indices.keys())
print(classification_report(y_true, y_pred, target_names=target_names, digits=4))

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10,8))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=target_names, yticklabels=target_names, cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('VGG16 Confusion Matrix')
plt.show()

"""## ***ResNET***"""

from tensorflow.keras.applications import ResNet50
from tensorflow.keras import layers, models, optimizers

# Load ResNet50 pretrained on ImageNet, without top layers
resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)

# Freeze all convolutional layers initially (feature extraction phase)
for layer in resnet_base.layers:
    layer.trainable = False

# Add custom dense layers on top
x = layers.GlobalAveragePooling2D()(resnet_base.output)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dropout(0.5)(x)
output = layers.Dense(NUM_CLASSES, activation='softmax')(x)

resnet_model = models.Model(inputs=resnet_base.input, outputs=output, name='resnet50_fruit')
resnet_model.summary()

resnet_model.compile(
    optimizer=optimizers.Adam(learning_rate=1e-3),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

resnet_checkpoint = '/content/drive/MyDrive/Colab Notebooks/FruitImageClassifierUsingCNN_ShaikNeelofar/best_resnet50.keras'
callbacks_resnet = [
    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
    ModelCheckpoint(resnet_checkpoint, monitor='val_loss', save_best_only=True)
]
EPOCHS = 15
history_resnet = resnet_model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=EPOCHS,
    callbacks=callbacks_resnet
)

# Unfreeze last few layers of ResNet50 for fine-tuning
for layer in resnet_base.layers[-10:]:   # unfreeze last 10 layers
    layer.trainable = True
# Compile with lower learning rate
resnet_model.compile(
    optimizer=optimizers.Adam(learning_rate=1e-5),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
# Train again briefly to fine-tune
history_resnet_ft = resnet_model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=5,
    callbacks=callbacks_resnet
)

resnet_loss, resnet_acc = resnet_model.evaluate(test_generator)
print(f"ResNet50 Test Accuracy: {resnet_acc*100:.2f}%")

# Plot combined curves (feature + fine-tune)
import matplotlib.pyplot as plt

plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plt.plot(history_resnet.history['accuracy'] + history_resnet_ft.history['accuracy'], label='train_acc')
plt.plot(history_resnet.history['val_accuracy'] + history_resnet_ft.history['val_accuracy'], label='val_acc')
plt.title('ResNet50 Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1,2,2)
plt.plot(history_resnet.history['loss'] + history_resnet_ft.history['loss'], label='train_loss')
plt.plot(history_resnet.history['val_loss'] + history_resnet_ft.history['val_loss'], label='val_loss')
plt.title('ResNet50 Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

test_steps = test_generator.samples // test_generator.batch_size + 1
y_prob = resnet_model.predict(test_generator, steps=test_steps)
y_pred = np.argmax(y_prob, axis=1)
y_true = test_generator.classes[:len(y_pred)]

target_names = list(class_indices.keys())
print(classification_report(y_true, y_pred, target_names=target_names, digits=4, zero_division=0))

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10,8))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=target_names, yticklabels=target_names, cmap='Greens')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('ResNet50 Confusion Matrix')
plt.show()